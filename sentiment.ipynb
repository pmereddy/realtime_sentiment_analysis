{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ec65f1-b2d9-4072-95bd-bc5a2e450743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.local/lib/python3.9/site-packages (22.3.1)\n",
      "Requirement already satisfied: transformers==4.25.1 in ./.local/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (4.25.1)\n",
      "Requirement already satisfied: torch==1.13.1 in ./.local/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /runtime-addons/cmladdon-2.0.34-b116/opt/cmladdons/python/site-packages (from transformers==4.25.1->-r requirements.txt (line 1)) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.9/site-packages (from transformers==4.25.1->-r requirements.txt (line 1)) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/site-packages (from transformers==4.25.1->-r requirements.txt (line 1)) (1.21.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from transformers==4.25.1->-r requirements.txt (line 1)) (2.25.1)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.9/site-packages (from transformers==4.25.1->-r requirements.txt (line 1)) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from transformers==4.25.1->-r requirements.txt (line 1)) (20.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.local/lib/python3.9/site-packages (from transformers==4.25.1->-r requirements.txt (line 1)) (0.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in ./.local/lib/python3.9/site-packages (from transformers==4.25.1->-r requirements.txt (line 1)) (0.11.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.9/site-packages (from transformers==4.25.1->-r requirements.txt (line 1)) (2022.10.31)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in ./.local/lib/python3.9/site-packages (from torch==1.13.1->-r requirements.txt (line 2)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in ./.local/lib/python3.9/site-packages (from torch==1.13.1->-r requirements.txt (line 2)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in ./.local/lib/python3.9/site-packages (from torch==1.13.1->-r requirements.txt (line 2)) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch==1.13.1->-r requirements.txt (line 2)) (4.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in ./.local/lib/python3.9/site-packages (from torch==1.13.1->-r requirements.txt (line 2)) (11.7.99)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->-r requirements.txt (line 2)) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->-r requirements.txt (line 2)) (58.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.25.1->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->transformers==4.25.1->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->transformers==4.25.1->-r requirements.txt (line 1)) (2020.11.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->transformers==4.25.1->-r requirements.txt (line 1)) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/site-packages (from requests->transformers==4.25.1->-r requirements.txt (line 1)) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!bash cdsw-build.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aca7d3d3-f7c8-4796-bc72-b2181c68a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c2c77f-36a1-49e9-9ffc-5fa194caa418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "sentiment_model = pipeline(task=\"sentiment-analysis\", model=MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c3c4246-fa63-4865-b689-ac502ea5af29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cdsw/.local/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:104: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'negative', 'score': 0.0042450143955647945},\n",
       "  {'label': 'neutral', 'score': 0.011172760277986526},\n",
       "  {'label': 'positive', 'score': 0.984582245349884}]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model(\"I love hackathons!\", return_all_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68495458-b123-437c-9ab5-52b197079530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List\n",
    "import logging\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "sentiment_model = pipeline(task=\"sentiment-analysis\", model=MODEL)\n",
    "\n",
    "def _get_max_score_label(scores: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Given a list of scores, where each score is a dictionary with keys 'label'\n",
    "    and 'score', the function returns the label with the maximum score.\n",
    "\n",
    "    Args:\n",
    "    scores (List[Dict]): List of scores, where each score is a dictionary with\n",
    "        keys 'label' and 'score'.\n",
    "\n",
    "    Returns:\n",
    "    str: The label with the maximum score\n",
    "\n",
    "    Example:\n",
    "    get_max_score_label([\n",
    "        {'label': 'negative', 'score': 0.0042450143955647945},\n",
    "        {'label': 'neutral', 'score': 0.011172760277986526},\n",
    "        {'label': 'positive', 'score': 0.984582245349884}\n",
    "    ])\n",
    "    Output: 'positive'\n",
    "    \"\"\"\n",
    "    max_score = max(scores, key=lambda x: x['score'])\n",
    "    return max_score['label']\n",
    "\n",
    "def predict(data: Dict[str, str]) -> Dict:\n",
    "    \"\"\"Run sentiment analysis on a given input text using a pre-trained model.\n",
    "\n",
    "    Args:\n",
    "    data (Dict[str, str]): The input data with at least the key \"text\" and value of\n",
    "        type string.\n",
    "\n",
    "    Returns:\n",
    "    Dict: The original dictionary with all keys and sentiment analysis results.\n",
    "\n",
    "    Example input:\n",
    "    {\n",
    "        \"created_at\":\"2023-01-11T15:05:45.000Z\",\n",
    "        \"id\":\"1613190434120949761\",\n",
    "        \"text\":\"I love hackathons!\"\n",
    "    }\n",
    "\n",
    "    Example output: \n",
    "\n",
    "    {\n",
    "        'created_at': '2023-01-11T15:05:45.000Z',\n",
    "        'id': '1613190434120949761',\n",
    "        'text': 'I love hackathons!',\n",
    "        'negative': 0.0042450143955647945,\n",
    "        'neutral': 0.011172760277986526,\n",
    "        'positive': 0.984582245349884\n",
    "    }\n",
    "\n",
    "    Raises:\n",
    "    TypeError: If data is not a dictionary.\n",
    "    TypeError: If data does not contain a key of \"text\".\n",
    "    TypeError: If data[\"text\"] is not a string.\n",
    "    \"\"\"\n",
    "\n",
    "    logging.info(\"begin parsing input data\")\n",
    "\n",
    "    if not isinstance(data, dict):\n",
    "        raise TypeError(\"data must be a dictionary\")\n",
    "    if \"text\" not in data:\n",
    "        raise TypeError(\"data must contain a key of 'text'\")\n",
    "\n",
    "    text = data[\"text\"]\n",
    "    if not isinstance(text, str):\n",
    "        raise TypeError(\"text must be a string\")\n",
    "\n",
    "    logging.info(\"end parsing input data without exceptions\")\n",
    "\n",
    "    logging.info(\"begin model inference\")\n",
    "    try:\n",
    "        predictions = sentiment_model(text, return_all_scores=True)[0]\n",
    "    except Exception as e:\n",
    "        logging.info(f\"end model inference with exception: {e}\")\n",
    "\n",
    "    logging.info(\"end model inference without exception\")\n",
    "\n",
    "    for p in predictions:\n",
    "        data[p[\"label\"]] = p[\"score\"]\n",
    "\n",
    "    data[\"label\"] = _get_max_score_label(predictions)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b69686f9-248b-4f16-8be6-6d760250365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.3 ms ± 111 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "predict({\"text\": \"I love hackathons\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "065a5f24-0b61-4130-951b-70224a6d70f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': '2023-01-11T15:05:45.000Z',\n",
       " 'id': '1613190434120949761',\n",
       " 'text': 'I love hackathons!',\n",
       " 'negative': 0.0042450143955647945,\n",
       " 'neutral': 0.011172760277986526,\n",
       " 'positive': 0.984582245349884,\n",
       " 'label': 'positive'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict({\n",
    "    \"created_at\":\"2023-01-11T15:05:45.000Z\",\n",
    "    \"id\":\"1613190434120949761\",\n",
    "    \"text\":\"I love hackathons!\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
